  ğŸš€ Improved Fraud Detection for E-commerce and Bank Transactions  
  By Firaol Delesa | 10 Academy: Artificial Intelligence Mastery    
  Adey Innovations Inc.  


   ğŸ“Œ Project Overview

This project aims to improve fraud detection in   e-commerce and banking transactions   by leveraging   machine learning, geolocation analysis, and transaction pattern recognition  . The goal is to build accurate, explainable models that balance   security   and   user experience  .

Using real-world datasets, we:
- Cleaned and preprocessed transaction data
- Engineered time-based and behavioral features
- Built and compared models (Logistic Regression vs Random Forest)
- Used   SHAP explainability   to interpret model decisions

The final model helps   prevent financial losses   while   building trust   with customers and institutions.

   ğŸ¯ Business Context

Fraud detection is a high-stakes challenge:
-   False positives   â†’ alienate legitimate customers
-   False negatives   â†’ lead to direct financial loss

This system enables:
- Real-time fraud monitoring
- Actionable insights for risk teams
- Transparent decision-making via model explainability

   ğŸ“ Project Structure

```
Improved_fraud_detection_for_e-commerce_and_bank_transactions/
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ Fraud_Data.csv                    E-commerce transaction data
â”‚   â”œâ”€â”€ IpAddress_to_Country.csv          IP range to country mapping
â”‚   â”œâ”€â”€ creditcard.csv                    Bank transaction data
â”‚   â”œâ”€â”€ merged_fraud_data.csv             Cleaned e-commerce data with country
â”‚   â””â”€â”€ cleaned_creditcard.csv            Cleaned bank data
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ random_forest_fraud_model.pkl     Trained Random Forest model
â”‚   â””â”€â”€ scaler.pkl                        Fitted StandardScaler
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ EDA.py                            Data cleaning, EDA, and preprocessing
â”‚   â”œâ”€â”€ Model_building.py                 Model training and evaluation
â”‚   â””â”€â”€ Shap_analysis.py                  SHAP explainability
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ shap_summary_plot.png             Global feature importance
â”‚   â”œâ”€â”€ shap_force_plot.png               Local prediction explanation
â”‚   â”œâ”€â”€ shap_dependence_ .png             Feature impact analysis
â”‚   â””â”€â”€ shap_feature_importance.csv       Top 10 features by SHAP value
â”‚
â”œâ”€â”€ README.md                             This file
â”œâ”€â”€ requirements.txt                      Python dependencies
â””â”€â”€ .gitignore
```

   ğŸ§  Key Features Engineered

| Feature | Description |
|-------|-------------|
| `time_since_signup` | Duration (in hours) between signup and purchase |
| `purchase_hour` | Hour of day when purchase occurred |
| `user_txn_count` | Number of transactions per user |
| `device_txn_count` | Number of transactions per device |
| `country` | Geolocation from IP address (via `IpAddress_to_Country.csv`) |

These features help identify suspicious behavior like:
- Immediate purchases after signup
- High transaction velocity
- Use of high-risk geolocations


   âš–ï¸ Handling Class Imbalance

Both datasets are highly imbalanced:
-   E-commerce  : 90.6% non-fraud, 9.4% fraud
-   Bank  : 99.8% non-fraud, 0.17% fraud

    Strategy:
- Applied   SMOTE + Random Undersampling   on the   training set only  
- Evaluated using   F1-Score, AUC-PR, ROC-AUC   instead of accuracy

> This ensures the model learns to detect rare fraud cases without overfitting.

   ğŸ¤– Model Comparison

| Model | F1-Score | AUC-PR | ROC-AUC | Interpretability |
|------|----------|--------|--------|------------------|
|   Logistic Regression   | 0.17 | 0.10 | 0.51 | âœ… High |
|   Random Forest   |   0.66   |   0.71   |   0.85   | âŒ Low (but fixed with SHAP) |

    âœ… Final Model:   Random Forest  

  Why?  
- Significantly higher F1-score and AUC-PR
- Better at capturing complex, non-linear fraud patterns
- When combined with SHAP, becomes   fully explainable  


   ğŸ” Model Explainability with SHAP

Used   SHAP (SHapley Additive exPlanations)   to interpret the Random Forest model:

    1.   SHAP Summary Plot  
![SHAP Summary Plot](reports/shap_summary_plot.png)  
 Top drivers of fraud: `time_since_signup`, `purchase_value`, `user_txn_count` 

    2.   SHAP Force Plot  
![SHAP Force Plot](reports/shap_force_plot.png)  
 Why a specific transaction was flagged as fraud 

    3.   SHAP Dependence Plots  
- `time_since_signup`: Short durations â†’ high fraud risk
- `purchase_value`: High amounts â†’ higher risk
- `user_txn_count`: Unusual frequency â†’ suspicious


   ğŸ“Š Key Insights

1.   Short `time_since_signup` is the strongest fraud predictor    
   â†’ Fraudsters often make purchases within minutes of signing up.

2.   High transaction velocity is a red flag    
   â†’ Users or devices with unusually high transaction counts are suspicious.

3.   Geolocation matters    
   â†’ Certain countries show higher fraud rates.

4.   Large purchases are riskier    
   â†’ High `purchase_value` increases fraud likelihood.

   ğŸ› ï¸ How to Run

    1. Clone the Repository
```bash
git clone https://github.com/FiraolD/Improved_fraud_detection_for_e-commerce_and_bank_transactions.git

cd Improved_fraud_detection_for_e-commerce_and_bank_transactions
```

    2. Install Dependencies
```bash
pip install -r requirements.txt
```

    3. Run the Full Pipeline
```bash
  Step 1: Data Analysis & Preprocessing
python src/EDA.py

  Step 2: Model Training
python src/Model_building.py

  Step 3: Model Explainability
python src/Shap_analysis.py
```

   ğŸ“¦ Requirements

```txt
pandas
numpy
matplotlib
seaborn
scikit-learn
imbalanced-learn
shap
joblib
```

Install with:
```bash
pip install -r requirements.txt
```

   ğŸ“… Key Dates (10 Academy)

| Task | Due Date |
|------|----------|
| Interim-1 Submission | 20 July 2025 |
| Interim-2 Submission | 27 July 2025 |
| Final Submission | 29 July 2025 |

   ğŸš€ Final Note

This project demonstrates a complete   end-to-end fraud detection pipeline   â€” from raw data to explainable AI. Itâ€™s ready for real-world deployment and further scaling.